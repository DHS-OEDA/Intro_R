---
title: "Functional Programming"
author: "Aaron C Cochran"
date: "April 23, 2018"
output: 
  html_document:
    toc: true
    toc_depth: 1
    toc_float: true
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(purrr)
library(broom)
```

# What is functional programming?

It's the ability to automate the boring stuff and avoid the problem of copying and pasting code for each iterative step in the analysis process. We could spend a whole class on this topic but this exercise will at least introduce you to the powers of functions in R. 

## An example

Using a mock dataset we can write a bunch of steps to rescale each column to have a range of 0 to 1. This code is almost all written in base R. Can you spot the mistake?  
 
```{r fun1}
df <- tibble::tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

df$a <- (df$a - min(df$a, na.rm = TRUE)) / 
  (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))
df$b <- (df$b - min(df$b, na.rm = TRUE)) / 
  (max(df$b, na.rm = TRUE) - min(df$a, na.rm = TRUE))
df$c <- (df$c - min(df$c, na.rm = TRUE)) / 
  (max(df$c, na.rm = TRUE) - min(df$c, na.rm = TRUE))
df$d <- (df$d - min(df$d, na.rm = TRUE)) / 
  (max(df$d, na.rm = TRUE) - min(df$d, na.rm = TRUE))
```

This is why copying/pasting is a bad practice. Too many opportunities for errors to be introduced, and the code is still not very readable. Yet each step of the code only has a single input, which means we can definitely simplify it. 


```{r fun2}
df <- tibble::tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}

rescale01(df)
```

By condensing the code into a function we can easily rescale the entire dataset in half the amount of code, and in a much more readble format. 

# `for` loops

Start with our random number `tibble` and compute the median of each column. 

```{r loop1}
df <- tibble::tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

median(df$a)
median(df$b)
median(df$c)
median(df$d)
```

As before, this method has 4 copies of the same code with a different column in each copy. It may be manageable with 4 columns, but much less so with 40.  So we'll use a `for` loop to fix this. 

```{r loop2}
output <- vector("double", ncol(df)) # 1. The output - create an output that is a vector of doubles
# and is as long as the number of columns in the data.frame

for(i in seq_along(df)) { # sequence - for each step along the df from col(1) to col(n)
  output[[i]] <- median(df[[i]]) # body - what we're doing at each iteration
}

output # display the output you defined. 
```

Some key points here:

1. The _output_: `output <- vector("double", length(x))`. Before running a loop you should allocate sufficient space for the output. This is much faster than growing the output organically using `c()`. 

2. The _sequence_: `i in seq_along(df)`. This determines what to loop over. Each run of the loop will assign `i` to a different value from `seq_along(df)`. The `seq_along()` function is a safer version of the base R `1:length(l)`; it is safer because it will give you the right answer with a 0 length vector. 

```{r loop3}
y <- vector("double", 0) # 0 length vector y
1:length(y) # wrong! This is not a length 2 vector with a 1 and a 0

seq_along(y) # correct! This is a vector of interger (doubles) of length 0. 
```

3. The _body_: `output[[i]] <- median(df[[i]])`. This is the workhorse in the function. The first iteration will run `output[[1]] <- median(df[[1]])` and the second iteration will run `output[[2]] <- median(df[[2]])`, etc. 

## Combining `for` loops into a function

Deeper down rabbit hole we go. We can take our `for` loop that calculates median and make it into a function that has more flexibility and can be assigned a name and called on demand. What if we want to be able to calculate a few summary stats from the same function?



```{r loop4}
col_summary <- function(df, fun) { # note this function takes 2 arguments, not one. 
  out <- vector("double", length(df))
  for (i in seq_along(df)) {
    out[i] <- fun(df[[i]])
  }
  out
}


col_summary(df, median)

col_summary(df, mean)

```

Loops are useful programming tools for doing things repeatedly. They're relatively intuitive to learn as well, which makes them appealing.  However, they are often a slow computing solution, and nested loops can be extremely difficult to debug.

# `apply` and friends
In base R, the `apply` family of functions (includes `apply`, `tapply`, `lapply` and `sapply`) allows for more efficient coding.  We first encountered these functions back in lesson 2, under Data Wrangling. 

Using an apply function over the rows in a data frame is essentially the same thing as a loop that scrolls through all of the rows in the data frame, but with fewer lines of code. 

Here's a large matrix to use for testing.
```{r apply1}
nr<-100000
mymat<-cbind(x = 1:nr, y = sort(rep(1:1000,length.out = nr)),z = nr:1, p = rnorm(nr))
summary(mymat)  
```

We can run a loop to extract a summary of the values in each row. 

```{r apply2}
time1<-system.time({
  outmat1<-matrix(0,nrow = nrow(mymat),ncol = 6)
  for(i in 1:nrow(mymat)){
    outmat1[i,]<-summary(mymat[i,])
  }
})
head(outmat1)
time1
```

That didn't seem too bad... `r time1["elapsed"]` seconds for `r format(nrow(mymat), big.mark = ",") ` rows processed. That's quite a lot of rows to summarize.

Let's see how it compares to the performance of the `apply` function. 

```{r apply3}
time2<-system.time(outmat2<-apply(mymat,1,summary))
all(outmat1 == t(outmat2))## check to make sure we got the same answer (the t function is because apply gives us a horizontal, rather than a vertical matrix.).
head(t(outmat2))
time2
```

Looks like `apply` is _slightly_ slower on my computer, which is a surprise to me.  However, the simplicity of the code is worth it.

# speeding things up with `snowfall`

Sometimes, you will want to run processes over more numbers, or you will want to do more complex calculations, or both.  When the work is very repetitive, you can also try speeding things up by running the job in parallel, with each CPU on your machine behaving like its' own little R instance, taking care of a different subset of rows in your matrix (or objects in your list for `lapply`).

There are a wide array of r packages aimed at speeding things up:

https://cran.r-project.org/web/views/HighPerformanceComputing.html

My favorite is the `snowfall` package, which is essentially a wrapper for the `snow` package, making it relatively easy to learn. The workflow is pretty straightforward:

1) Set up the cluster with `sfInit`. _You will need to specify how many cpus you want working._ 
2) Run your process with one of the `snowfall` variants of `apply` and friends.
3) Close down the cluster with `sfStop`.

```{r sf1}
library(snowfall)
time3<-system.time({
  sfInit(parallel = T, cpus = 6)
  outmat3<-sfApply(mymat,1,summary)
  sfStop()
})
time3
all(outmat1 == t(outmat3))
```

Despite the extra overhead in starting and stopping the cluster, using `snowfall` saved us `r  (time1 - time3)["elapsed"] ` seconds of elapsed time!  Imagine how useful this can be when your looped code runs for hours.

# The tidyverse version of `apply` and friends

This sort of work is so common in R that there is a nice package that does most of it for you. Still, understanding the fundamental code underneath is essential to really understanding how the `purrr` package's `map()` functions work.


# `purrr` 

This package enhances R's functional programming toolkit. The example below is a real-world example of what may be used in a workflow where you are testing the predictive power of a linear model across different segments of a dataset. It uses the `map()` function which maps another function across different columns in a `tbl_df` or `data.frame`. 

```{r purr1}
map_dbl(df, mean)
map_dbl(df, median)
map_dbl(df, sd)

```

We can pipe the `map()` functions as well, making the code even more readable.

```{r purr2}
df %>% map_dbl(mean)

df %>% map_dbl(median)

df %>% map_dbl(sd)

```

How is this better than our `col_summary` loop we wrote?

1. `purrr` functions are implemented in C, making them faster. 
2. The second argument, `.f`, the function to apply, can be a formula, a character vector, or an integer vector. 
3. Additional arugments can be passed to `.f` each time `map()` is called. 
4. The `map()` functions also preserve names. 

```{r purr3}
z <- list(x = 1:3, y=4:5)
map_int(z, length)

```


```{r purr4}
mtcars %>% 
  split(.$cyl) %>% # base R function to split the dataframe by cylinder
  map(~ lm(mpg ~ wt, data=.)) %>% # map a linear model of MPG ~ WEIGHT over each part of the dataset
  map(summary) %>% # summarise each part of the dataset
  map_dbl("r.squared") # extract the R^2 values for the linear model
```

